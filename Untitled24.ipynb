{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled24.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQnryne6ZM9y"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xygl2aF5Z-kp",
        "outputId": "88f960ad-2489-4909-90ff-322144cb1f86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzexF8RAcCM6",
        "outputId": "cc3ba18a-6f4f-4f01-f317-ae309bfada1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/shahroudy/NTURGB-D/master/Matlab/NTU_RGBD_samples_with_missing_skeletons.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-16 19:02:57--  https://raw.githubusercontent.com/shahroudy/NTURGB-D/master/Matlab/NTU_RGBD_samples_with_missing_skeletons.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6554 (6.4K) [text/plain]\n",
            "Saving to: ‘NTU_RGBD_samples_with_missing_skeletons.txt’\n",
            "\n",
            "\r          NTU_RGBD_   0%[                    ]       0  --.-KB/s               \rNTU_RGBD_samples_wi 100%[===================>]   6.40K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-11-16 19:02:57 (63.7 MB/s) - ‘NTU_RGBD_samples_with_missing_skeletons.txt’ saved [6554/6554]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P42zMx3zcF2R",
        "outputId": "421076db-918a-44d3-b21a-9449056868b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-25rGl20cYKG"
      },
      "source": [
        "!unzip -q /content/gdrive/My\\ Drive/nturgb+d_skeletons.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWPoo6NOwham"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rCUDZyhaBQe"
      },
      "source": [
        "data_path = \"nturgb+d_skeletons/\"\n",
        "broken_files_path = \"NTU_RGBD_samples_with_missing_skeletons.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJw1586IvUXX",
        "outputId": "8dfc4efe-66ba-43c1-997f-d3928bc8073e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "class Skeleton_Dataset(Dataset):\n",
        "    joints_framework = ['neck', 'nose', 'mid_hip',\n",
        "                         'l_sho', 'l_elb',\n",
        "                         'l_wri', 'l_hip',\n",
        "                         'l_knee', 'l_ank',\n",
        "                         'r_sho', 'r_elb',\n",
        "                         'r_wri', 'r_hip',\n",
        "                         'r_kne', 'r_ank',\n",
        "                         'r_eye', 'l_eye',\n",
        "                         'r_ear', 'l_ear']\n",
        "\n",
        "\n",
        "        joints_framework_in_work = ['nose','l_sho', 'l_elb','l_wri','r_sho','r_elb', 'r_wri', 'l_hip','l_knee','l_ank','r_hip','r_kne','r_ank','neck']\n",
        "        upper_joints_framework = ['nose','l_sho', 'l_elb','l_wri','r_sho','r_elb', 'r_wri', 'l_hip','l_knee','l_ank','r_hip','r_kne','r_ank','neck']\n",
        "\n",
        "\n",
        "\n",
        "        SKELETON_EDGES = np.array([[11, 10], [10, 9], [9, 0], [0, 3], [3, 4], [4, 5], [0, 6], [6, 7], [7, 8], [0, 12],\n",
        "                                       [12, 13], [13, 14], [1, 14], [1, 15], [15, 16], [1, 17], [17, 18]])\n",
        "        \n",
        "        \n",
        "        \n",
        "        bone_pairs = (\n",
        "            (1, 2), (2, 21), (3, 21), (4, 3), (5, 21), (6, 5),\n",
        "            (7, 6), (8, 7), (9, 21), (10, 9), (11, 10), (12, 11),\n",
        "            (13, 1), (14, 13), (15, 14), (16, 15), (17, 1), (18, 17),\n",
        "            (19, 18), (20, 19), (22, 23), (21, 21), (23, 8), (24, 25),(25, 12)\n",
        "        )\n",
        "\n",
        "        bone_pairs_in_work = (\n",
        "            (1, 14), \n",
        "            (14, 2), (2, 3), (3, 4),\n",
        "            (14, 5), (5, 6), (6, 7), \n",
        "            (14, 8), (8, 9), (9, 10),\n",
        "            (14, 11), (11, 12), (12, 13))\n",
        "\n",
        "\n",
        "        joints_names = ['spinebase', 'spinemid', 'neck', 'head','l_sho', 'l_elb','l_wri','l_hand','r_sho','r_elb', 'r_wri', 'r_hand','l_hip','l_knee','l_ank','l_fool','r_hip','r_knee','r_ank','r_foot','spineshoulder','l_tip','l_thumb','r_tip','r_thunb']\n",
        "        joints_in_work = [ 'head','l_sho', 'l_elb','l_wri','r_sho','r_elb', 'r_wri', 'l_hip','l_knee','l_ank','r_hip','r_knee','r_ank','spineshoulder']\n",
        "        upper_joints = [ 'head','l_sho', 'l_elb','l_wri','r_sho','r_elb', 'r_wri', 'l_hip','l_knee','l_ank','r_hip','r_knee','r_ank','spineshoulder']\n",
        "        \n",
        "        \n",
        "        ##### список файлов с лейблами на каждый файл \n",
        "        working_files_with_labels, action_classes = read_data(data_path, broken_files_path)\n",
        "        \n",
        "        LABELS = {v: k for k, v in action_classes.items()}\n",
        "    \n",
        "    \n",
        "    def __init__(self, data_path, broken_files_path=None, training_classes=None,\n",
        "                 num_joint = 25, max_frame = 300, transform=None):\n",
        "        self.data_path = data_path\n",
        "        self.broken_files_path = broken_files_path\n",
        "        self.training_classes = training_classes\n",
        "        self.training_subjects = training_subjects\n",
        "        self.training_cameras = training_cameras\n",
        "        self.transform = transform\n",
        "        self.read_data(data_path, broken_files_path)\n",
        "        self.build_dataframe()\n",
        "        self.labels = self.data.iloc[:,-1]\n",
        "        \n",
        "        \n",
        "    def read_data(self, data_path, broken_files_path):\n",
        "        labels = []\n",
        "        files = []\n",
        "        action_classes = {}\n",
        "        counter = 0\n",
        "        files_counter = {}\n",
        "\n",
        "        with open(broken_files_path, 'r') as f:\n",
        "            broken_files = f.read().split(\"\\n\")\n",
        "\n",
        "        raw_files = os.listdir(data_path)\n",
        "        num_frames = 0\n",
        "\n",
        "        for filename in raw_files:\n",
        "            if filename not in broken_files:\n",
        "                action_class = int(filename[filename.find('A') + 1:filename.find('A') + 4])\n",
        "                subject_id = int(filename[filename.find('P') + 1:filename.find('P') + 4])\n",
        "                camera_id = int(filename[filename.find('C') + 1:filename.find('C') + 4])\n",
        "                if action_class in training_classes and camera_id in training_cameras: \n",
        "                    if action_class in action_classes:\n",
        "                        if files_counter[action_class] < 120:\n",
        "                            files.append([filename,action_classes[action_class]])\n",
        "                            files_counter[action_class] = files_counter[action_class] + 1\n",
        "                    else:\n",
        "                        action_classes.update({action_class : counter})\n",
        "                        files_counter.update({action_class : 1})\n",
        "                        counter+=1\n",
        "                        files.append([filename,action_classes[action_class]])\n",
        "    #                     labels.append([action_class])\n",
        "        print(\"action classes: \", action_classes)\n",
        "        print(\"action files: \", files_counter)\n",
        "        \n",
        "        self.files = files\n",
        "        self.action_classes = action_classes\n",
        "\n",
        "#         return files, action_classes\n",
        "\n",
        "    def get_nonzero_std(self, s): \n",
        "        index = s.sum(-1).sum(-1) != 0  \n",
        "        s = s[index]\n",
        "        if len(s) != 0:\n",
        "            s = s[:, :, 0].std() + s[:, :, 1].std() + s[:, :, 2].std()  \n",
        "        else:\n",
        "            s = 0\n",
        "        return s\n",
        "\n",
        "\n",
        "    def read_skeleton_filter(self, file):\n",
        "        with open(file, 'r') as f:\n",
        "            skeleton_sequence = {}\n",
        "            skeleton_sequence['numFrame'] = int(f.readline())\n",
        "            skeleton_sequence['frameInfo'] = []\n",
        "            for t in range(skeleton_sequence['numFrame']):\n",
        "                frame_info = {}\n",
        "                frame_info['numBody'] = int(f.readline())\n",
        "                frame_info['bodyInfo'] = []\n",
        "\n",
        "                for m in range(frame_info['numBody']):\n",
        "                    body_info = {}\n",
        "                    body_info_key = [\n",
        "                        'bodyID', 'clipedEdges', 'handLeftConfidence',\n",
        "                        'handLeftState', 'handRightConfidence', 'handRightState',\n",
        "                        'isResticted', 'leanX', 'leanY', 'trackingState'\n",
        "                    ]\n",
        "                    body_info = {\n",
        "                        k: float(v)\n",
        "                        for k, v in zip(body_info_key, f.readline().split())\n",
        "                    }\n",
        "                    body_info['numJoint'] = int(f.readline())\n",
        "                    body_info['jointInfo'] = []\n",
        "                    for v in range(body_info['numJoint']):\n",
        "                        joint_info_key = [\n",
        "                            'x', 'y', 'z', 'depthX', 'depthY', 'colorX', 'colorY',\n",
        "                            'orientationW', 'orientationX', 'orientationY',\n",
        "                            'orientationZ', 'trackingState'\n",
        "                        ]\n",
        "                        joint_info = {\n",
        "                            k: float(v)\n",
        "                            for k, v in zip(joint_info_key, f.readline().split())\n",
        "                        }\n",
        "                        body_info['jointInfo'].append(joint_info)\n",
        "                    frame_info['bodyInfo'].append(body_info)\n",
        "                skeleton_sequence['frameInfo'].append(frame_info)\n",
        "        return skeleton_sequence\n",
        "\n",
        "\n",
        "    def read_xyz(self, file, max_body=1, num_joint=25):\n",
        "        seq_info = self.read_skeleton_filter(file)\n",
        "        data = np.zeros((max_body, seq_info['numFrame'], num_joint, 3))\n",
        "        for n, f in enumerate(seq_info['frameInfo']):\n",
        "            for m, b in enumerate(f['bodyInfo']):\n",
        "                for j, v in enumerate(b['jointInfo']):\n",
        "                    if m < max_body and j < num_joint:\n",
        "                        data[m, n, j, :] = [v['x'], v['y'], v['z']]\n",
        "\n",
        "                    else:\n",
        "                        pass\n",
        "        return data\n",
        "\n",
        "\n",
        "    def create_coords_blocks(self, test_file, chonk_len = 45):   \n",
        "        frame_counter = 0\n",
        "        new_labels = []\n",
        "        new_frames = []\n",
        "        blocks = []\n",
        "\n",
        "        test_frames = self.read_xyz(data_path + test_file[0])[0]\n",
        "        label = test_file[1]\n",
        "        slice_len = chonk_len * int(len(test_frames)/chonk_len)\n",
        "\n",
        "\n",
        "        for index in range(len(test_frames[:slice_len])):\n",
        "            frame_counter += 1\n",
        "            new_frames.append(test_frames[index].flatten())\n",
        "            if frame_counter == chonk_len:\n",
        "                frame_counter = 0\n",
        "                blocks.append(np.array(new_frames))\n",
        "                new_labels = new_labels + [label]\n",
        "                new_frames = []\n",
        "        return blocks, new_labels\n",
        "        \n",
        "    \n",
        "    def build_dataframe(self):\n",
        "        \n",
        "        data = []\n",
        "        labels = []\n",
        "        numbers = {v: 0 for k, v in self.action_classes.items()}\n",
        "        for file in self.files:\n",
        "            frames_blocks, label = self.create_coords_blocks(file)\n",
        "#             print(frames_blocks, label)\n",
        "            if label != [] and numbers[label[0]] <= 150:\n",
        "                numbers[label[0]] = numbers[label[0]] + len(label)\n",
        "                data = data + frames_blocks\n",
        "                labels = labels + label\n",
        "        data_np = np.asarray(data)\n",
        "        labels_np = np.asarray(labels)\n",
        "\n",
        "        data_sq = data_np.reshape(len(data_np), -1)\n",
        "        test_data = pd.DataFrame(data_sq)\n",
        "        test_labels = pd.DataFrame(labels_np)\n",
        "        test_data['labels'] = test_labels\n",
        "        self.LABELS = {v: k for k, v in self.action_classes.items()}\n",
        "        self.data = test_data\n",
        "           \n",
        "    def __len__(self):\n",
        "         return len(self.data)\n",
        "        \n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        item = np.asarray(self.data.iloc[idx,:-1]).reshape(45,75)\n",
        "        label = self.labels[idx]\n",
        "        if self.transform != None:\n",
        "            item = transform(item)\n",
        "        return (item, label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-72-451c288d4dc4>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    joints_framework_in_work = ['nose','l_sho', 'l_elb','l_wri','r_sho','r_elb', 'r_wri', 'l_hip','l_knee','l_ank','r_hip','r_kne','r_ank','neck']\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sTA1SxavXwl"
      },
      "source": [
        "class LSTM_net(nn.Module):\n",
        "    def __init__(self,input_dim,hidden_dim,output_dim,layer_num):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.lstm = torch.nn.LSTM(input_dim, hidden_dim,layer_num,batch_first=True)\n",
        "        self.dr = torch.nn.Dropout2d(0.1)\n",
        "        self.fc = torch.nn.Linear(hidden_dim,output_dim)\n",
        "        \n",
        "        \n",
        "    def forward(self,inputs):\n",
        "        x = inputs\n",
        "        lstm_out,(hn,cn) = self.lstm(x)\n",
        "        out = self.fc(lstm_out[:,-1,:])\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovp73AD_vaTt"
      },
      "source": [
        "training_subjects = list(range(0, 28)) #количество людей выполняющих действия\n",
        "training_classes = [8, 10, 22, 23, 27, 21, 32, 5, 3, 16] #классы которые будем использовать для обучения, полный список прдставлен тут https://github.com/shahroudy/NTURGB-D\n",
        "training_cameras = [1, 2, 3] \n",
        "\n",
        "max_body_true = 1\n",
        "max_body_kinect = 1\n",
        "\n",
        "num_joint = 25\n",
        "max_frame = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9WtlaX0vcmt",
        "outputId": "5d9272b2-e4d2-42d1-a311-0b839e666287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset = Skeleton_Dataset(data_path, broken_files_path, training_classes, transform=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "action classes:  {16: 0, 21: 1, 22: 2, 27: 3, 8: 4, 5: 5, 10: 6, 32: 7, 3: 8, 23: 9}\n",
            "action files:  {16: 120, 21: 120, 22: 120, 27: 120, 8: 120, 5: 120, 10: 120, 32: 120, 3: 120, 23: 120}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8WOQoGAxfa7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTRSx_FpvfVZ"
      },
      "source": [
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(0.75*len(dataset)), len(dataset) - int(0.75*len(dataset))])\n",
        "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M9oIza5vihu",
        "outputId": "2a8c1817-8a1d-4aff-c01e-1b40d13b5c33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_hidden = 128\n",
        "n_joints = 25*3\n",
        "LABELS = {x: training_classes[x] for x in range(len(training_classes))}\n",
        "n_categories = len(LABELS)\n",
        "n_layer = 2\n",
        "rnn = LSTM_net(n_joints,n_hidden,n_categories,n_layer)\n",
        "rnn.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM_net(\n",
              "  (lstm): LSTM(75, 128, num_layers=2, batch_first=True)\n",
              "  (dr): Dropout2d(p=0.1, inplace=False)\n",
              "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "briE9QRRvnMZ"
      },
      "source": [
        "def categoryFromOutput(output):\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item()\n",
        "#     print(output.topk(5))\n",
        "    return LABELS[category_i], category_i\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPF8SgrDvqsZ",
        "outputId": "cc6ada62-bb2b-420e-a949-b47894b9e643",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch import optim\n",
        "import time\n",
        "import math\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.0007\n",
        "optimizer = optim.SGD(rnn.parameters(),lr=learning_rate,momentum=0.9)\n",
        "\n",
        "all_losses = []\n",
        "start = time.time()\n",
        "counter = 0\n",
        "for epoch in range(60):  \n",
        "    current_loss = 0\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        \n",
        "        inputs, labels = data[0].to(device), data[1].to(device).type(torch.LongTensor).to(device)\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "        output = rnn(inputs.float())\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step() \n",
        "\n",
        "\n",
        "        current_loss += loss.item()\n",
        "        category = {x: training_classes[x] for x in range(len(training_classes))}[int(labels[0])]\n",
        "\n",
        "        if counter % 500 == 0:\n",
        "            guess, guess_i = categoryFromOutput(output)\n",
        "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "            print('epoch : %d iter : %d  %.4f  / %s %s' % (epoch, i, loss, guess, correct))\n",
        "\n",
        "        \n",
        "        counter = counter + 1\n",
        "    if counter % 100 == 0:\n",
        "        all_losses.append(current_loss / 25)\n",
        "        current_loss = 0"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 0 iter : 0  1.6038  / 8 ✓\n",
            "epoch : 7 iter : 52  1.9564  / 27 ✓\n",
            "epoch : 15 iter : 40  1.6127  / 8 ✗ (21)\n",
            "epoch : 23 iter : 28  1.4999  / 3 ✗ (32)\n",
            "epoch : 31 iter : 16  1.4899  / 22 ✓\n",
            "epoch : 39 iter : 4  1.8485  / 22 ✓\n",
            "epoch : 46 iter : 56  2.0498  / 27 ✓\n",
            "epoch : 54 iter : 44  1.4646  / 8 ✓\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZOSD1a2vupb"
      },
      "source": [
        "class LSTM_net(nn.Module):\n",
        "    def __init__(self,input_dim,hidden_dim,output_dim,layer_num):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.lstm1 = torch.nn.LSTM(input_dim, hidden_dim, layer_num,batch_first=True)\n",
        "        self.dr1 = torch.nn.Dropout2d(0.5)\n",
        "        self.lstm2 = torch.nn.LSTM(input_dim, hidden_dim)\n",
        "        self.dr2 = torch.nn.Dropout2d(0.5)\n",
        "        self.fc = torch.nn.Linear(hidden_dim,output_dim)\n",
        "        \n",
        "        \n",
        "    def forward(self,inputs):\n",
        "        x = inputs\n",
        "        lstm_out1,(hn,cn) = self.lstm1(x)\n",
        "        lstm_out2,(hn,cn) = self.lstm2(x)\n",
        "        out = self.fc(lstm_out2[:,-1,:])\n",
        "        return out"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciXSjDLjvvLg",
        "outputId": "c78094a8-6f66-47fa-a13d-faa80e0a760a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_hidden = 324\n",
        "n_joints = 25*3\n",
        "n_categories = len({x: training_classes[x] for x in range(len(training_classes))})\n",
        "n_layer = 2\n",
        "rnn = LSTM_net(n_joints,n_hidden,n_categories,n_layer)\n",
        "rnn.to(device)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM_net(\n",
              "  (lstm1): LSTM(75, 324, num_layers=2, batch_first=True)\n",
              "  (dr1): Dropout2d(p=0.5, inplace=False)\n",
              "  (lstm2): LSTM(75, 324)\n",
              "  (dr2): Dropout2d(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=324, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s31aSq3qvxWY",
        "outputId": "b9ac922a-5bec-4e76-d388-6ab060997a88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.001\n",
        "optimizer = optim.SGD(rnn.parameters(),lr=learning_rate,momentum=0.9)\n",
        "\n",
        "all_losses = []\n",
        "start = time.time()\n",
        "counter = 0\n",
        "for epoch in range(60):  \n",
        "    current_loss = 0\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        \n",
        "        inputs, labels = data[0].to(device), data[1].to(device).type(torch.LongTensor).to(device)\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "        output = rnn(inputs.float())\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step() \n",
        "\n",
        "\n",
        "        current_loss += loss.item()\n",
        "        category = {x: training_classes[x] for x in range(len(training_classes))}[int(labels[0])]\n",
        "\n",
        "        if counter % 500 == 0:\n",
        "            guess, guess_i = categoryFromOutput(output)\n",
        "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "            print('epoch : %d iter : %d (%s) %.4f  / %s %s' % (epoch, i, timeSince(start), loss, guess, correct))\n",
        "\n",
        "        \n",
        "        counter = counter + 1\n",
        "    if counter % 100 == 0:\n",
        "        all_losses.append(current_loss / 25)\n",
        "        current_loss = 0"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 0 iter : 0 (0m 0s) 2.3250  / 32 ✗ (27)\n",
            "epoch : 7 iter : 52 (1m 19s) 2.2545  / 5 ✗ (3)\n",
            "epoch : 15 iter : 40 (2m 37s) 2.2597  / 5 ✗ (23)\n",
            "epoch : 23 iter : 28 (3m 56s) 2.2841  / 3 ✓\n",
            "epoch : 31 iter : 16 (5m 14s) 2.0788  / 22 ✓\n",
            "epoch : 39 iter : 4 (6m 32s) 2.1603  / 22 ✗ (32)\n",
            "epoch : 46 iter : 56 (7m 52s) 1.9841  / 3 ✓\n",
            "epoch : 54 iter : 44 (9m 11s) 1.6194  / 22 ✓\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuFfJUFr1Ffs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}